---
title: "Linear combiner training on random subsets of different sizes"
output:
  pdf_document: default
  html_notebook: default
bibliography: references.bib
---

```{r}
library(ggplot2)
library(dplyr)
library(scales)
```

Experiment code is in the file training_subsets_sizes_experiment.py.
Experiment on both CIFAR10 and CIFAR100 datasets.
This experiment trains WeightedLinearEnsemble on various subsets of different sizes of data on which neural networks were trained.
Four different coupling methods are used: method one and two (m1 and m2) from [@wu2004probability], Bayes covariant method (bc) from [@vsuch2016bayes]
and a coupling method by Such, Benus and Tinajova (sbt) from [@vsuch2015new].
Three combining methods are used: lda, logreg and logreg_no_interc which employ linear discriminant analysis or logistic regression
individually on each pair of classes.
Goal of this experiment is to determine, for which size of the combiner training set, the ensemble achieves the best performance.
The requirement of lda, that the predictors are normally distributed is not met by more than half of the class pairs.
This may be reflected in the worsened prediction capacity of ensembles using lda combining method and we will consider these ensembles as less influential on the decision of the training set size.


```{r}
metrics <- c("accuracy", "nll", "ece")
```

# CIFAR-10
```{r}
ens_metrics_c10 <- read.csv("../data/data_tv_5000_c10/0/exp_subsets_sizes_train_outputs/ens_metrics.csv", stringsAsFactors=TRUE)
nets_metrics_c10 <- read.csv("../data/data_tv_5000_c10/0/exp_subsets_sizes_train_outputs/net_metrics.csv", stringsAsFactors=TRUE)
```


```{r}
for (cp_m in unique(ens_metrics_c10$coupling_method))
{
  for (metric in metrics)
  {
    box_plt <- ens_metrics_c10 %>% filter(coupling_method==cp_m) %>%
      ggplot() +
      geom_boxplot(mapping=aes_string(x="train_size", y=metric, group="train_size")) +
      facet_grid(rows=vars(combining_method), scales="free") +
      scale_x_log10(breaks=log_breaks(n=10)) +
      ggtitle(paste0("Comparison of ", metric, " over different combining methods\n for coupling method ", cp_m))
    
    print(box_plt)
  } 
}
```

As we can see on these plots, accuracy varies only slightly over different training set sizes.
The differences among median accuracies are only about 0.15% for logistic regression combining methods and
a little more for lda. The difference in accuracy of 0.15% represents only 15 samples of the test set of size 10000,
therefore we don't consider these differences to provide conclusive information for the choice of training set size.

However, if we look at the metrics negative log likelihood (nll) and estimated calibration error (ece) we can see
a short decrease or stagnation followed by a clear increasing trend for logreg combining methods and mostly stagnating trend for combining method lda.
This decrease, or stagnation changes into increase at training set size of about 500.


# CIFAR-100
```{r}
ens_metrics_c100 <- read.csv("../data/data_tv_5000_c100/0/exp_subsets_sizes_train_outputs/ens_metrics.csv", stringsAsFactors=TRUE)
nets_metrics_c100 <- read.csv("../data/data_tv_5000_c100/0/exp_subsets_sizes_train_outputs/net_metrics.csv", stringsAsFactors=TRUE)
```


```{r}
for (cp_m in unique(ens_metrics_c10$coupling_method))
{
  for (metric in metrics)
  {
    box_plt <- ens_metrics_c100 %>% filter(coupling_method==cp_m) %>%
      ggplot() +
      geom_boxplot(mapping=aes_string(x="train_size", y=metric, group="train_size")) +
      facet_grid(rows=vars(combining_method), scales="free") +
      scale_x_log10(breaks=log_breaks(n=10)) +
      ggtitle(paste0("Comparison of ", metric, " over different combining methods\n for coupling method ", cp_m))
    
    print(box_plt)
  } 
}
```

Differences in accuracy are again rather small for combining methods logreg.
For nll and ece we can observe a decrease followed by stagnation or increase for larger
training set sizes. 

From these results and considering the practical coputational burden
we conclude to use training set size 500 for CIFAR-10 and 5000 for CIFAR-100.
These sizes are consistent in providing 50 samples per class.